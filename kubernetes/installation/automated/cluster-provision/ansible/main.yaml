- hosts: 127.0.0.1
  connection: local
  tasks:
  - name: Rescan SSH key
    #description: "Rescan the keys for newly created Hosts to avoid overlapping if they exist already"
    shell:
      cmd: "ssh-keygen -R {{ item }} && ssh-keyscan -H {{ item }} >> ~/.ssh/known_hosts"
    with_items: "{{ groups['all'] }}"

- hosts: all
  remote_user: locthp
  become: true
  roles:
   - common_handlers
   - essential
   - { role: haproxy, when: "inventory_hostname in groups['haproxy']" }
   - { role : external-bgp-router, when: "inventory_hostname in groups['external-bgp-router']"}
   - { role: k8s-tools, when: "inventory_hostname in groups['k8s-masters'] or inventory_hostname in groups['k8s-workers']" }
   - { role: first-master-initialization, when: "groups['k8s-masters'][0] == inventory_hostname"}
   - { role: master-nodes-joining, when: "groups['k8s-masters'][0] != inventory_hostname and inventory_hostname in groups['k8s-masters']"}
   - { role: worker-nodes-joining, when: "inventory_hostname in groups['k8s-workers']" }
   


- hosts: 127.0.0.1
  connection: local
  roles:
  - common_handlers
  tasks:
  - name: Store kubeconfig on admin's machine
    fetch:
      src: /etc/kubernetes/admin.conf
      dest: ~/.kube/{{ hostvars[groups['k8s-masters'][0]]['cluster_name'] }}.conf
      flat: true
    delegate_to: "{{ groups['k8s-masters'][0] }}"
    become: true
    connection: ssh
    remote_user: locthp
  - name: Install CNI Plugin
    shell:
      cmd: "kubectl --kubeconfig ~/.kube/{{ hostvars[groups['k8s-masters'][0]]['cluster_name'] }}.conf apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml"
  
  - name: Check status and wait for cluster to be ready
    shell:
      cmd: "kubectl --kubeconfig ~/.kube/{{ hostvars[groups['k8s-masters'][0]]['cluster_name'] }}.conf get nodes --no-headers"
    register: node_status
    until:  "node_status.stdout_lines | select('search', 'NotReady') | list | length == 0"
    retries: 10
    delay: 10
  - name: Install Metallb
    shell:
      cmd: "kubectl --kubeconfig ~/.kube/{{ hostvars[groups['k8s-masters'][0]]['cluster_name'] }}.conf apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.7/config/manifests/metallb-native.yaml"
  - name: Check status of Metallb and wait for pods to be ready
    shell:
      cmd: "kubectl --kubeconfig ~/.kube/{{ hostvars[groups['k8s-masters'][0]]['cluster_name'] }}.conf get pods -n metallb-system --no-headers"
    register: metallb_status
    until:  "metallb_status.stdout_lines | reject('search', '1/1') | list | length == 0"
    retries: 100
    delay: 5

  - name: Apply configuration
    block:
      - template:
          src: templates/metallb/configuration.j2
          dest: files/metallb/configuration.yaml
      - shell:
          cmd: "kubectl --kubeconfig ~/.kube/{{ hostvars[groups['k8s-masters'][0]]['cluster_name'] }}.conf apply -f ./files/metallb/configuration.yaml "
  - name: Show the output
    debug:
      msg: "{{ node_status.stdout_lines }}"
  - name: Initialize Discord Message
    set_fact:
      discord_message: "Cluster {{ hostvars[inventory_hostname]['cluster_name'] }} has been successfully provisioned:\n"
  - name: Append status of each node
    set_fact: 
      discord_message: "{{ discord_message + item + '\n' }}"
    with_items: "{{ node_status.stdout_lines }}"
  - name: Send message to Discord
    debug:
      msg: "Updating Discord with the cluster status....."
    changed_when: true
    notify:
      - Prepare content of message
      - Set dashes
      - Add dashes
      - Send Discord message

  

